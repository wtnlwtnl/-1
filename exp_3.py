import numpy as np
import time
from collections import Counter

def read_dataset(file_path):
    """è¯»å–å¹¶å¤„ç†æ•°æ®é›†"""
    data = np.loadtxt(file_path)
    features = data[:, :256]  # å›¾åƒç‰¹å¾
    labels_onehot = data[:, 256:]  # ç‹¬çƒ­ç¼–ç æ ‡ç­¾
    labels = np.argmax(labels_onehot, axis=1)  # è½¬ä¸ºæ•°å­—æ ‡ç­¾
    return features, labels

def euclidean_distance(test_data, train_data):
    """æ¬§å‡ é‡Œå¾—è·ç¦» - ä¿®å¤ç‰ˆæœ¬"""
    distances = np.zeros((test_data.shape[0], train_data.shape[0]))
    for i in range(test_data.shape[0]):
        diff = test_data[i] - train_data
        distances[i] = np.sqrt(np.sum(diff ** 2, axis=1))
    return distances

def manhattan_distance(test_data, train_data):
    """æ›¼å“ˆé¡¿è·ç¦» - ä¿®å¤ç‰ˆæœ¬"""
    distances = np.zeros((test_data.shape[0], train_data.shape[0]))
    for i in range(test_data.shape[0]):
        diff = np.abs(test_data[i] - train_data)
        distances[i] = np.sum(diff, axis=1)
    return distances

def chebyshev_distance(test_data, train_data):
    """åˆ‡æ¯”é›ªå¤«è·ç¦» - ä¿®å¤ç‰ˆæœ¬"""
    distances = np.zeros((test_data.shape[0], train_data.shape[0]))
    for i in range(test_data.shape[0]):
        diff = np.abs(test_data[i] - train_data)
        distances[i] = np.max(diff, axis=1)
    return distances

def minkowski_distance(test_data, train_data, p=3):
    """é—µå¯å¤«æ–¯åŸºè·ç¦» (p=3) - ä¿®å¤ç‰ˆæœ¬"""
    distances = np.zeros((test_data.shape[0], train_data.shape[0]))
    for i in range(test_data.shape[0]):
        diff = np.abs(test_data[i] - train_data)
        distances[i] = np.power(np.sum(np.power(diff, p), axis=1), 1.0/p)
    return distances

def cosine_distance(test_data, train_data):
    """ä½™å¼¦è·ç¦» - ä¼˜åŒ–ç‰ˆæœ¬"""
    eps = 1e-8
    
    # è®¡ç®—èŒƒæ•°
    test_norms = np.linalg.norm(test_data, axis=1, keepdims=True) + eps
    train_norms = np.linalg.norm(train_data, axis=1) + eps
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
    dot_products = np.dot(test_data, train_data.T)
    cosine_similarities = dot_products / (test_norms * train_norms)
    
    # è½¬æ¢ä¸ºè·ç¦»
    distances = 1 - cosine_similarities
    return distances

def classify_knn(distance_matrix, train_labels, k_neighbors):
    """åŸºäºè·ç¦»çŸ©é˜µçš„kNNåˆ†ç±»"""
    num_test = distance_matrix.shape[0]
    results = np.zeros(num_test, dtype=int)
    
    for idx in range(num_test):
        # è·å–kä¸ªæœ€è¿‘é‚»çš„ç´¢å¼•
        neighbor_idx = np.argpartition(distance_matrix[idx], k_neighbors)[:k_neighbors]
        neighbor_labels = train_labels[neighbor_idx]
        # æŠ•ç¥¨å†³å®šç±»åˆ«
        vote_count = Counter(neighbor_labels)
        results[idx] = vote_count.most_common(1)[0][0]
    
    return results

def cross_validation_loo(data_x, data_y, k_val, distance_func):
    """æ‰§è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯"""
    sample_count = len(data_x)
    correct_count = 0
    
    for i in range(sample_count):
        # æ„å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
        test_x = data_x[i:i+1]
        train_x = np.vstack([data_x[:i], data_x[i+1:]])
        train_y = np.hstack([data_y[:i], data_y[i+1:]])
        
        # è®¡ç®—è·ç¦»å¹¶åˆ†ç±»
        dist = distance_func(test_x, train_x)
        pred = classify_knn(dist, train_y, k_val)[0]
        
        if pred == data_y[i]:
            correct_count += 1
    
    return correct_count / sample_count

def evaluate_test_set(train_x, train_y, test_x, test_y, optimal_k, distance_func):
    """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    dist_matrix = distance_func(test_x, train_x)
    predictions = classify_knn(dist_matrix, train_y, optimal_k)
    accuracy = np.mean(predictions == test_y)
    return accuracy

def main():
    # æ•°æ®åŠ è½½
    try:
        train_features, train_labels = read_dataset('semeion_train.txt')
        test_features, test_labels = read_dataset('semeion_test.txt')
    except FileNotFoundError as e:
        print(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return
    
    # è·ç¦»æ–¹æ³•é…ç½®
    distance_methods = {
        'æ¬§å‡ é‡Œå¾—è·ç¦»': euclidean_distance,
        'æ›¼å“ˆé¡¿è·ç¦»': manhattan_distance,
        'åˆ‡æ¯”é›ªå¤«è·ç¦»': chebyshev_distance,
        'é—µå¯å¤«æ–¯åŸºè·ç¦»': minkowski_distance,
        'ä½™å¼¦è·ç¦»': cosine_distance
    }
    
    # å‚æ•°è®¾ç½®
    k_candidates = [1, 3, 5, 7, 9, 11, 13, 15]
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = {}
    best_overall_score = -1
    best_overall_method = None
    best_overall_k = None
    
    # å¯¹æ¯ç§è·ç¦»æ–¹æ³•è¿›è¡Œè¯„ä¼°
    for method_name, distance_func in distance_methods.items():
        print(f'\næ­£åœ¨è¯„ä¼° {method_name}...')
        
        accuracy_scores = []
        
        # å¯¹å½“å‰è·ç¦»æ–¹æ³•è¿›è¡Œkå€¼è®¨è®º
        for k in k_candidates:
            score = cross_validation_loo(train_features, train_labels, k, distance_func)
            accuracy_scores.append(score)
        
        # æ‰¾åˆ°å½“å‰è·ç¦»æ–¹æ³•çš„æœ€ä½³kå€¼
        optimal_idx = np.argmax(accuracy_scores)
        best_k = k_candidates[optimal_idx]
        best_score = accuracy_scores[optimal_idx]
        
        # å­˜å‚¨å½“å‰æ–¹æ³•çš„ç»“æœ
        all_results[method_name] = {
            'scores': accuracy_scores,
            'best_k': best_k,
            'best_score': best_score
        }
        
        # æ›´æ–°å…¨å±€æœ€ä¼˜ç»“æœ
        if best_score > best_overall_score:
            best_overall_score = best_score
            best_overall_method = method_name
            best_overall_k = best_k
        
        # è¾“å‡ºå½“å‰è·ç¦»æ–¹æ³•çš„ç»“æœè¡¨æ ¼
        print('=' * 60)
        print(f'{method_name} - è®­ç»ƒé›†LOOéªŒè¯ç»“æœæ±‡æ€»')
        print('=' * 60)
        print('kå€¼\tå‡†ç¡®ç‡\t\tç™¾åˆ†æ¯”')
        print('-' * 40)
        
        for i, (k, acc) in enumerate(zip(k_candidates, accuracy_scores)):
            star = ' â­' if i == optimal_idx else ''
            print(f'{k}\t{acc:.4f}\t\t{acc*100:.2f}%{star}')
        
        print(f'\n{method_name} æœ€ä¼˜ç»“æœ: k={best_k}, å‡†ç¡®ç‡={best_score:.4f} ({best_score*100:.2f}%)')
    
    # è¾“å‡ºå…¨å±€æœ€ä¼˜ç»“æœ
    print('\n' + '=' * 70)
    print('è®­ç»ƒé›†å…¨å±€æœ€ä¼˜ç»“æœ')
    print('=' * 70)
    print(f'ğŸ† æœ€ä½³è·ç¦»æ–¹æ³•: {best_overall_method}')
    print(f'ğŸ¯ æœ€ä½³kå€¼: {best_overall_k}')
    print(f'ğŸ“ˆ æœ€é«˜å‡†ç¡®ç‡: {best_overall_score:.4f} ({best_overall_score*100:.2f}%)')
    
    # ä½¿ç”¨æœ€ä¼˜å‚æ•°åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯
    best_distance_func = distance_methods[best_overall_method]
    test_accuracy = evaluate_test_set(train_features, train_labels, test_features, test_labels, 
                                    best_overall_k, best_distance_func)
    print(f'ğŸ“Š æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')

if __name__ == '__main__':
    main()